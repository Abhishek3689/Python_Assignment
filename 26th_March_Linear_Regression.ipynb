{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "557c73f0-c0c9-4b8c-bb45-a6a9e3815c16",
   "metadata": {},
   "source": [
    "## Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4585180-5d64-4344-9f93-857107fcbc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple Linear Regression: In this regression there is only one independent variable and one dependent variable \n",
    "# equation:  y=mx+c\n",
    "## for eg. to predict the price of a house , area is independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b28d627-0b59-49dd-8df4-5feefa025a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiple Linear Regression: In this regression there is more than 1 independent variables and one dependant variable\n",
    "## Equation:  y=m1x1+m2x2+....+mnxn+c\n",
    "## for eg. To predict Price of a house ,independent variables Area,Location,BHK can be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea3f8cf-3b69-44c8-93f7-09875fe1c64d",
   "metadata": {},
   "source": [
    "## Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c56edb91-d916-48b2-bb4c-45494fa7f53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There should be linear and additive relationship between dependent and independent variables\n",
    "## This can be checked by plotting scatter between each independent variable and dependend variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9498f951-ec65-4352-9a43-9322072becad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There should not be any multicollinearity meaning no independent variables should be correlated\n",
    "## This can be checked by correlation matirx of independent features or by heatmap. if correlation is higher between any independent variabel good to drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6d2c396-96b4-4fa9-a3aa-4fe83d3e2de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normality of Residual\n",
    "## This can be chekd by distribution plot - if it shows normal bell shaped then holds good our assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a34b8260-1920-4e2b-9b38-e196e0b9bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Homoscedasiticity among the data:\n",
    "## This can be checked by plotting scatter plot between predicted output with residual if this does not show any kind of pattern then assumption holds good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5544905b-f5af-4bac-afca-b8835da7682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## No autocorealton\n",
    "## While a scatterplot allows you to check for autocorrelations, you can test the linear regression model for autocorrelation with the Durbin-Watson test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f83e7e-2839-4084-9db0-e3935aa5dd8c",
   "metadata": {},
   "source": [
    "## Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "665047ee-576c-4d7e-a87b-d43c7d3e14aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The slope indicates the steepness of a line and the intercept indicates the location where it intersects an axis. \n",
    "## The slope and the intercept define the linear relationship between two variables, and can be used to estimate an average rate of change. \n",
    "## The greater the magnitude of the slope, the steeper the line and the greater the rate of change\n",
    "## Equation : y=mx+c\n",
    "## y=4-.5x This example shows the slope is -ve when x increases by 1 ,y decreases by .5. The y intercept is 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe654b2-f786-4b82-a7cd-307212e5b24a",
   "metadata": {},
   "source": [
    "## Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2d1aa7-99c8-4b3c-9f38-49764c9c8e88",
   "metadata": {},
   "source": [
    "##### Gradient Descent : It is the Optimization process which is used to reduce the cost function of a model by iteratively adjusting its parameters in the opposite direction of the gradient.\n",
    "##### Cost function is defined as the difference between actual output and predicted output.\n",
    "##### The goal of the gradient descent algorithm is to minimize the given function (say cost function). To achieve this goal, it performs two steps iteratively:\n",
    "    ## Compute the gradient (slope), the first order derivative of the function at that point\n",
    "    ## Make a step (move) in the direction opposite to the gradient, opposite direction of slope increase from the current point by alpha times the gradient at that point\n",
    "    \n",
    "##### How Gradient Descent Work   \n",
    "1. Gradient descent is an optimization algorithm used to minimize the cost function of a model.\n",
    "2. The cost function measures how well the model fits the training data and is defined based on the difference between the predicted and actual values.\n",
    "3. The gradient of the cost function is the derivative with respect to the modelâ€™s parameters and points in the direction of the steepest ascent.\n",
    "4. The algorithm starts with an initial set of parameters and updates them in small steps to minimize the cost function.\n",
    "5. In each iteration of the algorithm, the gradient of the cost function with respect to each parameter is computed.\n",
    "6. The gradient tells us the direction of the steepest ascent, and by moving in the opposite direction, we can find the direction of the steepest descent.\n",
    "7. The size of the step is controlled by the learning rate, which determines how quickly the algorithm moves towards the minimum.\n",
    "8. The process is repeated until the cost function converges to a minimum, indicating that the model has reached the optimal set of parameters.\n",
    "9. There are different variations of gradient descent, including batch gradient descent, stochastic gradient descent, and mini-batch gradient descent, each with its own advantages and limitations.\n",
    "10. Efficient implementation of gradient descent is essential for achieving good performance in machine learning tasks. The choice of the learning rate and the number of iterations can significantly \n",
    "    impact the performance of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f908680-d3f2-4072-9f70-36cb6ba9cbec",
   "metadata": {},
   "source": [
    "## Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45e53dfe-a2b0-429b-bcf2-4b05d6811c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## In Multiple Linear Regression Model multiple independent features are used to Predict Output (Dependent Variable)\n",
    "## AS Explained in Questin 1, while siple regression uses only one independt feature to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd966908-6117-4464-8aa4-25c90f1eb1ea",
   "metadata": {},
   "source": [
    "## Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25ee4f0f-2394-4396-8eaa-62cf27e32857",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multicollinearlity : if we are building a model and there are independent features which are haing higher correation with each other then this is said to have multicolinearity\n",
    "    ## Multicollinearity causes the following two basic types of problems\n",
    "## 1.The coefficient estimates can swing wildly based on which other independent variables are in the model. The coefficients become very sensitive to small changes in the model.\n",
    "## 2.Multicollinearity reduces the precision of the estimated coefficients, which weakens the statistical power of your regression model. \n",
    "    ## You might not be able to trust the p-values to identify independent variables that are statistically significant.\n",
    "## We can check this by using correlation matrix /heatmap of independent features or by using Variation inflation factors(VIF) from statsmodel. If it is higher let say greater than 10  then multicollineariity is critical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073476dd-9b4f-4752-b378-f74bea51e3a8",
   "metadata": {},
   "source": [
    "## Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4d449b2-2799-414d-93e8-c24e420c94cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A simple linear regression algorithm only works when the relationship between the data is linear.\n",
    "## But suppose we have non-linear data, then linear regression will not be able to draw a best-fit line. Simple regression analysis fails in such conditions.\n",
    "## In polynomial regression, the relationship between the dependent variable and the independent variable is modeled as an nth-degree polynomial function. \n",
    "## When the polynomial is of degree 2, it is called a quadratic model; when the degree of a polynomial is 3, it is called a cubic model, and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ee3968-e331-4ee3-bccd-a0519fadae10",
   "metadata": {},
   "source": [
    "## Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6934f6-1b09-4ff5-9cf7-9cb07da8219b",
   "metadata": {},
   "source": [
    "- A polynomial regression model is a machine learning model that can capture non-linear relationships between variables by fitting a non-linear regression line, which may not be possible with simple linear regression.\n",
    "- It is used when linear regression models may not adequately capture the complexity of the relationship.\n",
    "- It can be useful in various fields, such as finance, physics, engineering, and social sciences, where there may be nonlinear relationships between variables.\n",
    "\n",
    "####    Disadvatages\n",
    "- Overfitting: Polynomial regression models can easily become overfit to the data, especially when using high-degree polynomials.\n",
    "- Nonlinear relationships: Polynomial regression models are only appropriate for modeling nonlinear relationships that can be approximated by a polynomial curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae50a7e6-4e30-4be8-ba17-d0b51518a7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
